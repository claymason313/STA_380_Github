test_drop
# Loop through the train words and add those not in test to the vector test_add
for (word in X_words) {
if (!word %in% X_test_words) {
test_add <- c(test_add, word)
}
}
test_add
# Create a matrix of 0's to insert into the test matrix
zero <- matrix(0, nrow = nrow(X_train), ncol=length(test_add))
# Name the columns using the words in test_add
colnames(zero) <- test_add
# Add the zero matrix to the test matrix
X2_test = cbind(X_test, zero)
# Sort the columns alphabetically so they match the X2
X2_test = X2_test[,order(colnames(X2_test))]
X2_test
# Drop the words in test_drop from the test matrix
X2_test = X2_test[,!colnames(X2_test) %in% test_drop]
X2_test
test_drop
# Create a dense matrix
X = as.matrix(DTM_train)
# Calculate the smoothing factor
smooth_count = 1/nrow(X)
nrow(X)
smooth_count
colnames(X)
labels_train
#ugh I believe this is where my issue lies
# Add the smoothing factor and aggregate the word counts + smoothing factor for each author
by_word_wc = rowsum(X + smooth_count, labels_train)
by_word_wc
smooth_count
X
# Sum the word counts + smoothing factor for each word for each author
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
# Add the prediction the the matrix
log_prob = cbind(log_prob, predict)
# Create a column that checks the prediction against the actual
accurate = as.integer(rownames(log_prob) == log_prob[,51])
# Create a dataframe that includes the actual, prediction, and accuracy
nb_results = cbind.data.frame(rownames(log_prob), predict, accurate)
mean(accurate)
mean(accurate)/100
nb_results
log_prob
colnames(log_prob)
rm(list=ls())
## The tm library and related plugins comprise R's most popular text-mining stack.
## See http://cran.r-project.org/web/packages/tm/vignettes/tm.pdf
## tm has many "reader" functions.  Each one has
## arguments elem, language, id
## (see ?readPlain, ?readPDF, ?readXML, etc)
## This wraps another function around readPlain to read
## plain text documents in English.
readerPlain = function(fname){
readPlain(elem=list(content=readLines(fname)),
id=fname, language='en') }
# Import libraries
library(tm)
library(SnowballC)
library(plyr)
library(tm)
library(magrittr)
library(slam)
library(proxy)
library(glmnet)
library(nnet)
# Roll directories together into a single corpus
## "globbing" = expanding wild cards in filename paths
setwd("/Users/claytonmason/GitHub/STA_380_Clay/Data")
file_list_import_train = Sys.glob('../data/ReutersC50/C50train/*')
# Loop through file_list_import_train to get the files and the authors
file_list_train = c()
labels_train = c()
for(author_train in file_list_import_train) {
author_name_train = substring(author_train, first=29)
files_to_add_train = Sys.glob(paste0(author_train, '/*.txt'))
file_list_train = append(file_list_train, files_to_add_train)
labels_train = append(labels_train, rep(author_name_train, length(files_to_add_train)))
}
file_list_train
# Read in file_list and remove .txt from the file name
all_docs_train = lapply(file_list_train, readerPlain)
names(all_docs_train) = file_list_train
names(all_docs_train) = sub('.txt', '', names(all_docs_train))
## once you have documents in a vector, you
## create a text mining 'corpus' with:
my_corpus_train = Corpus(VectorSource(all_docs_train))
#ugh - https://stackoverflow.com/questions/40462805/names-function-in-r-not-working-as-expected
#https://stackoverflow.com/questions/10566473/names-attribute-must-be-the-same-length-as-the-vector
length(my_corpus_train)
length(labels_train)
names(my_corpus_train) = labels_train
labels_train
## Some pre-processing/tokenization steps.
## tm_map just maps some function to every document in the corpus
my_corpus_train = tm_map(my_corpus_train, content_transformer(tolower)) # make everything lowercase
my_corpus_train = tm_map(my_corpus_train, content_transformer(removeNumbers)) # remove numbers
my_corpus_train = tm_map(my_corpus_train, content_transformer(removePunctuation)) # remove punctuation
my_corpus_train = tm_map(my_corpus_train, content_transformer(stripWhitespace)) # remove excess white-space
my_corpus_train = tm_map(my_corpus_train, content_transformer(removeWords), stopwords("SMART")) # remove stop words
my_corpus_train = tm_map(my_corpus_train, stemDocument) # combine stem words
# Create a document term matrix
DTM_train = DocumentTermMatrix(my_corpus_train)
DTM_train # some basic summary statistics
# a special kind of sparse matrix format
class(DTM_train)
## You can inspect its entries...
inspect(DTM_train[1:10,1:20])
## ...find words with greater than a min count...
findFreqTerms(DTM_train, 100)
## ...or find words whose count correlates with a specified word.
findAssocs(DTM_train, "fed", .5)
# Remove sparse terms
DTM_train = removeSparseTerms(DTM_train, 0.94)
DTM_train
# Create a dense matrix
X_train = as.matrix(DTM_train)
X_train
########### repeat steps for test data
file_list_import_test = Sys.glob('../data/ReutersC50/C50test/*')
#  get the files and the authors
file_list_test = c()
labels_test = c()
for(author_test in file_list_import_test) {
author_name_test = substring(author_test, first=29)
files_to_add_test = Sys.glob(paste0(author_test, '/*.txt'))
file_list_test = append(file_list_test, files_to_add_test)
labels_test = append(labels_test, rep(author_name_test, length(files_to_add_test)))
}
file_list_test
# Read in file_list and remove .txt from the file name
all_docs_test = lapply(file_list_test, readerPlain)
names(all_docs_test) = file_list_test
names(all_docs_test) = sub('.txt', '', names(all_docs_test))
all_docs_test
## once you have documents in a vector, you
## create a text mining 'corpus' with:
my_corpus_test = Corpus(VectorSource(all_docs_test))
#ugh - https://stackoverflow.com/questions/40462805/names-function-in-r-not-working-as-expected
#https://stackoverflow.com/questions/10566473/names-attribute-must-be-the-same-length-as-the-vector
length(my_corpus_test)
length(labels_test)
names(my_corpus_test) = labels_test
## Some pre-processing/tokenization steps.
## tm_map just maps some function to every document in the corpus
my_corpus_test = tm_map(my_corpus_test, content_transformer(tolower)) # make everything lowercase
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeNumbers)) # remove numbers
my_corpus_test = tm_map(my_corpus_test, content_transformer(removePunctuation)) # remove punctuation
my_corpus_test = tm_map(my_corpus_test, content_transformer(stripWhitespace)) # remove excess white-space
my_corpus_test = tm_map(my_corpus_test, content_transformer(removeWords), stopwords("SMART")) # remove stop words
my_corpus_test = tm_map(my_corpus_test, stemDocument) # combine stem words
# Create a document term matrix
DTM_test = DocumentTermMatrix(my_corpus_test)
DTM_test # some basic summary statistics
# a special kind of sparse matrix format
class(DTM_test)
## You can inspect its entries...
inspect(DTM_test[1:10,1:20])
## ...find words with greater than a min count...
findFreqTerms(DTM_test, 50)
## ...or find words whose count correlates with a specified word.
findAssocs(DTM_test, "fed", .5)
# Remove sparse terms
DTM_test = removeSparseTerms(DTM_test, 0.94)
DTM_test
# Create a dense matrix
X_test = as.matrix(DTM_test)
X_test
# Get the list of words in the training set
X_words = colnames(X_train)
X_words
# Get the list of words in the test set
X_test_words = colnames(X_test)
X_test_words
# Create 2 empty vectors to store words to add to test and words to drop from test
test_add = vector(length=0)
test_drop = vector(length=0)
# Loop through the test words and add those not in the train to the vector test_drop
for (test_word in X_test_words) {
if (!test_word %in% X_words) {
test_drop <- c(test_drop, test_word)
}
}
test_drop
# Loop through the train words and add those not in test to the vector test_add
for (word in X_words) {
if (!word %in% X_test_words) {
test_add <- c(test_add, word)
}
}
test_add
# Create a matrix of 0's to insert into the test matrix
zero <- matrix(0, nrow = nrow(X_train), ncol=length(test_add))
# Name the columns using the words in test_add
colnames(zero) <- test_add
# Add the zero matrix to the test matrix
X2_test = cbind(X_test, zero)
# Sort the columns alphabetically so they match the X2
X2_test = X2_test[,order(colnames(X2_test))]
X2_test
# Drop the words in test_drop from the test matrix
X2_test = X2_test[,!colnames(X2_test) %in% test_drop]
X2_test
# Create a dense matrix
X = as.matrix(DTM_train)
# Calculate the smoothing factor
smooth_count = 1/nrow(X)
nrow(X)
smooth_count
colnames(X)
labels_train
#ugh I believe this is where my issue lies
# Add the smoothing factor and aggregate the word counts + smoothing factor for each author
by_word_wc = rowsum(X + smooth_count, labels_train)
by_word_wc
smooth_count
X
# Sum the word counts + smoothing factor for each word for each author
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
X2
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
# Add the prediction the the matrix
log_prob = cbind(log_prob, predict)
# Create a column that checks the prediction against the actual
accurate = as.integer(rownames(log_prob) == log_prob[,52])
accurate = as.integer(rownames(log_prob) == log_prob[,51])
accurate
log_prob
colnames(log_prob)
predict
log_prob = cbind(log_prob, predict)
colnames(log_prob)
w = log(w)
by_word_wc = rowsum(X + smooth_count, labels_train)
by_word_wc
smooth_count
X
# Sum the word counts + smoothing factor for each word for each author
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
X2
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
# Add the prediction the the matrix
log_prob = cbind(log_prob, predict)
log_prob
# Create a column that checks the prediction against the actual
accurate = as.integer(rownames(log_prob) == log_prob[,51])
accurate
accurate = as.integer(rownames(log_prob) == log_prob[,51])
accurate
# Create a dataframe that includes the actual, prediction, and accuracy
nb_results = cbind.data.frame(rownames(log_prob), predict, accurate)
nb_results
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
# Add the prediction the the matrix
log_prob = cbind(log_prob, predict)
log_prob
# Create a column that checks the prediction against the actual
accurate = as.integer(rownames(log_prob) == log_prob[,51])
accurate
by_word_wc = rowsum(X + smooth_count, labels_train)
by_word_wc
smooth_count
X
# Sum the word counts + smoothing factor for each word for each author
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
X2
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
log_prob = cbind(predict)
log_prob
# Create a column that checks the prediction against the actual
accurate = as.integer(rownames(log_prob) == log_prob[,51])
accurate = as.integer(rownames(log_prob) == log_prob[,50])
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
X2
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
# Add the prediction the the matrix
log_prob = cbind(log_prob, predict)
log_prob
# Create a column that checks the prediction against the actual
accurate = as.integer(rownames(log_prob) == log_prob[,51])
accurate
log_prob[,51]
rownames(log_prob)
log_prob[,51]
rownames(log_prob)
accurate = as.integer(rownames(log_prob) == rownames(log_prob[,51]))
accurate
by_word_wc = rowsum(X + smooth_count, labels_train)
by_word_wc
smooth_count
X
# Sum the word counts + smoothing factor for each word for each author
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
X2
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
# Add the prediction the the matrix
log_prob = cbind(log_prob, predict)
log_prob
# Create a column that checks the prediction against the actual
accurate = (rownames(log_prob) == log_prob[,51])
accurate
log_prob
by_word_wc = rowsum(X + smooth_count, labels_train)
by_word_wc
smooth_count
X
# Sum the word counts + smoothing factor for each word for each author
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
X2
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
# Add the prediction the the matrix
log_prob2 = cbind(log_prob, predict)
log_prob2
# Create a column that checks the prediction against the actual
accurate = (rownames(log_prob) == log_prob[,51])
accurate
by_word_wc = rowsum(X + smooth_count, labels_train)
by_word_wc
smooth_count
X
# Sum the word counts + smoothing factor for each word for each author
total_wc = rowSums(by_word_wc)
total_wc
#### my issue trickles down to here
#  multinomial probability vector
w = by_word_wc / total_wc
w
# Log the vector for easier interpretability
w = log(w)
w
# Set X2 equal to the multinomial probability vector w
X2 = w
# Transpose the multinomial probability vector for matrix multiplication
X2 = t(X2)
X2
# Multiply the test matrix by X2
log_prob = X2_test %*% X2
colnames(log_prob)
# Get the prediction by return the column name of the max value for each document
predict = colnames(log_prob)[max.col(log_prob)]
predict
# Add the prediction the the matrix
log_prob = cbind(log_prob, predict)
log_prob
# Create a column that checks the prediction against the actual
accurate = (rownames(log_prob) == log_prob[,51])
accurate
# Create a dataframe that includes the actual, prediction, and accuracy
nb_results = cbind.data.frame(rownames(log_prob), predict, accurate)
nb_results
# Return the total accuracy
mean(accurate)
# Add column names to dataframe
colnames(nb_results) <- c("Actual","Prediction","Accuracy")
# Create a summary of each actual and prediction combination with the number of instances (n) and the percentage of that outcome occuring for each author
length <- ddply(nb_results, .(Actual), transform, sum.n = length(Actual))
table <- ddply(length, .(Actual, Prediction), summarise, n=length(Prediction), percentage=n / sum.n[1] * 100)
table
accurate = as.integer(rownames(log_prob) == log_prob[,51]))
accurate
accurate = as.integer(rownames(log_prob) == log_prob[,51])
accurate
X_train2 = as.matrix(DTM_train)
X_train2 = X_train2/rowSums(X_train2)
pca_X_train2 = prcomp(X_train2, scale=TRUE)
pca_X_train2$rotation[order(abs(pca_X_train2$rotation[,1]),decreasing=TRUE),1][1:25]
pca_X_train2$rotation[order(abs(pca_X_train2$rotation[,2]),decreasing=TRUE),2][1:25]
pca_X_train2$rotation[order(abs(pca_X_train2$rotation[,2]),decreasing=TRUE),2]
pca_X_train2$rotation[order(abs(pca_X_train2$rotation[,1]),decreasing=TRUE),1]
pca_X_train2$rotation[order(abs(pca_X_train2$rotation[,2]),decreasing=TRUE),2]
pca_X_train2$x[,1:2]
# Plot the first two PCs..
plot(pca_X_train2$x[,1:2], xlab="PCA 1 direction", ylab="PCA 2 direction", bty="n",
type='n')
text(pca_X_train2$x[,1:2], labels = 1:length(all_docs_train), cex=0.7)
identify(pca_X_train2$x[,1:2], n=4)
# 5-dimensional word vectors
word_vectors = pca_X_train2$rotation[,1:5]
word_vectors[982,]
# Set A = training DTM
A = X_train
# Set b = actual author names
b = rownames(X_train)
# Run PCA scaled
pc_words = prcomp(A, scale=TRUE)
# Check how many principle components
dim(pc_words$rotation)
# Calculate scores
